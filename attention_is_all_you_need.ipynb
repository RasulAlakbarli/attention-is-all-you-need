{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is all you need\n",
    "\n",
    "### Rasul Alakbarli, Mahammad Nuriyev, Petko Petkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General `Module` class so we always have access to the device used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module(nn.Module):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the embeddings in the transformer architecture (both `input` and `output` with the positional encodings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(Module):\n",
    "    def __init__(self, d_model, vocab_len, pad_index, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_len, self.d_model, padding_idx=pad_index)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding shape: (batch, sequence_len, d_model)\n",
    "        # Positional encoding shape: (sequence_len, d_model)\n",
    "        return self.dropout(self.embedding(x) + self.positional_encoding(x))\n",
    "\n",
    "    def positional_encoding(self, x):\n",
    "        # result.shape = (seq_len, d_model)\n",
    "        result = torch.zeros(\n",
    "            (x.size(1), self.d_model),\n",
    "            dtype=torch.float,\n",
    "            requires_grad=False\n",
    "        )\n",
    "\n",
    "        # pos.shape = (seq_len, 1)\n",
    "        pos = torch.arange(0, x.size(1)).unsqueeze(1)\n",
    "\n",
    "        # dim.shape = (d_model)\n",
    "        dim = torch.arange(0, self.d_model, step=2)\n",
    "\n",
    "        # Sine for even positions, cosine for odd dimensions\n",
    "        result[:, 0::2] = torch.sin(pos / (10_000 ** (dim / self.d_model)))\n",
    "        result[:, 1::2] = torch.cos(pos / (10_000 ** (dim / self.d_model)))\n",
    "        return result.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of feed-forward neural network which is used in both of the encoder and decoder parts in the transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(Module):\n",
    "    def __init__(self, d_model, d_ff=2048):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.relu(self.linear1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
